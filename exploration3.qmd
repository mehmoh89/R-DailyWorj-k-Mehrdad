---
title: 'Exploration 3: Description of Relationships II'
author: 'Mehrdad Mohammadi'
date: '`r format(Sys.Date(), "%B %d, %Y")`'
header-includes:
    - \usepackage[T1]{fontenc}
    - \usepackage{textcomp}
    - \usepackage{fontspec}
    - \newfontfamily\unicodefont[Ligatures=TeX]{TeX Gyre Heros}
    - \newfontfamily\grouptwofont[Ligatures=TeX]{Source Code Pro}
    - \newfontfamily\groupthreefont[Ligatures=TeX]{Courier}
output:
  pdf_document:
    number_sections: true
    fig_caption: yes
    fig_height: 8
    fig_width: 8
    latex_engine: xelatex
    citation_package: biblatex
    keep_tex: true
fontsize: 10pt
geometry: margin=1in
graphics: yes
mainfont: "Helvetica"
#bibliography: classbib.bib
#biblio-style: "authoryear-comp,natbib"
---

<!-- Make this document using library(rmarkdown); render("exploration2.Rmd") -->
\input{mytexsymbols} 

Loads a separate .tex file with your custom symbols/commands (probably math symbols).

```{r setup, echo=FALSE, results=FALSE, include=FALSE, cache=FALSE}
library(here)  # helps with file paths
source(here("qmd_setup.R")) #qmd_setup.R is a setup script meant to centralize and standardize the configuration for my Quarto/R Markdown projects. Instead of repeating the same code (like loading packages, setting plotting themes, or defining helper functions) in every .qmd file, you keep those commands in qmd_setup.R. Then, each document can simply call.

library(tidyverse) # data wrangling, visualization, etc.
```
- `echo=FALSE` → hides code in output.
- `results=FALSE` → hides output results.
- `include=FALSE` → nothing from this chunk appears in the document.
- `cache=FALSE` → avoids caching results (runs fresh every time).
- `library(here)` → makes file paths relative to project root.
- `source(here("qmd_setup.R"))` → runs a custom setup script (likely sets themes, options, etc.).
- `library(tidyverse)` → loads core R packages for data wrangling/plotting.

---


This week we are using [Pippa Norris's amazing
data at the level of the country](https://www.pippanorris.com/data) the DEMOCRACY CROSS-NATIONAL DATA, RELEASE 4.0 FALL 2015.


Here is some reading that might be useful:
- @james2013introduction \url{https://www.statlearning.com/} (Chap 3 and 7 in
  particular)
- \href{https://www.john-fox.ca/Companion/appendices.html}{The Fox and Weisberg
  Textbook Nonparametric Regression Appendix}

```{r}
library(readstata13)

dat <- read.dta13(
  "https://www.dropbox.com/s/huhqag5rudwtbno/Democracy%20Cross-National%20Data%20V4.1%2009092015.dta?dl=1",
  nonint.factors = TRUE,
  generate.factors = TRUE
)
table(dat$Lang2, useNA = "ifany")
table(dat$Lang3, useNA = "ifany")
table(dat$Dissap, useNA = "ifany")
```

#Initial Warning (Non-Integer Factor Codes)
R warned that some variables used floating-point codes for factors and that no labels had been assigned. This meant categorical variables were not being read properly.

Fix Attempt (Custom Import Options)
I re-ran the import using two options:

nonint.factors = TRUE → allowed non-integer factor codes.

generate.factors = TRUE → generated missing labels automatically.
With these adjustments, the dataset successfully loaded.

Second Warning (Duplicate Factor Levels)
A new warning appeared, noting duplicated factor levels for three variables: Lang2, Lang3, and Dissap. R handled this automatically by generating unique labels so each level could be distinguished.

Final Outcome (Clean Import)
After these fixes, the dataset loaded correctly. The warnings were informational, not fatal errors, and the data is now ready for analysis.


```{r}
#library(readstata13)
#dat <- read.dta13("https://www.dropbox.com/s/huhqag5rudwtbno/Democracy%20Cross-National%20Data%20V4.1%2009092015.dta?dl=1")
## Make sure each row is a state and there are no duplicates
#stopifnot(length(unique(dat$Nation)) == nrow(dat))
#stopifnot(all(table(dat$Nation) == 1))
```

1. Choose one continous variable as an "outcome". I'm calling it $y_i$ for
   country $i=1 \ldots 195$ in this data set. This variable should have at
   least 4 values and hopefully more. Please describe this variable (you can
   use words, tables, single numbers, etc.. to describe this variable alone, in
   one-dimension).

2. Choose another variable which should cause the outcome according to some
   theory or another. I'm calling it $z_i$ (again where $i$ indexes country).
   (If you can state the theory, great. If not, then just an intuition about
   why $z_i \rightarrow y_i$ will work. It is ok if you yourself don't think
   $z_i$ should relate to $y_i$, but someone should. There should be something
   at stake in learning about this relationship.) This variable, which I'll
   call the "explanatory variable", should also be continuous (i.e. at least 4
   unique values). Please describe this variable (you can use words, tables,
   single numbers, etc.. to describe this variable alone, in
   one-dimension).^[Notice that I'm not saying "dependent variable" or
   "independent variable" because I don't think that $z_i$ has values that are
   "independent" of anything in particular.]


3. Please describe the relationship between $y_i$ and $z_i$ using both graphs
   and at least two global linear smoothers (FYI least squares is a global
   linear smoother). Explain why you made the choices you made. (For example,
   if you considered a third and fourth approach to linear description, explain
   why you didn't use those approaches and instead chose the ones that you did.
   You can use least squares of course, or not. As you see fit given the data.)
   Notice that these are all the countries of the world: the whole population
   of countries. Not a sample.

4. Please also describe this relationship using a non-linear, local smoother.
   Please use 10-fold cross-validation to choose the tuning parameter(s) for
   this smoother. Explain in your own words what cross-validation is and why
   one would use it to choose tuning parameters in this case or in general.
   
   ##
   1) Outcome  $y_i$: Politystand2014
Politystand2014 measures regime characteristics in 2014 and varies widely across countries, making it a suitable continuous outcome.

2) Explanatory  $z_i$: CBINDEX
CBINDEX captures governance quality; theory suggests stronger governance is linked to higher democracy scores.

3) Global linear relationship
Scatterplots with OLS and robust regression show a generally positive slope; the robust fit checks sensitivity to outliers.

4) Local non-linear relationship
A LOESS smoother with span chosen by 10-fold cross-validation highlights possible non-linear patterns beyond the linear fits.
##

```{r}
## Some examples of a tidy approach to cross-validation here using loess for my
## local non-parametric smoother.
## There are many other approaches online. Feel free to use them
## if you find them easier to understand.

library(modelr)

##Brings in modelr, which provides functions like crossv_kfold() for tidy cross-validation.

small_dat <- select(dat, Nation, Politystand2014, CBINDEX)
## remove some labels and such arriving from stata from the small data
## Keeps only three variables: Nation (country name/ID), Politystand2014 (political regime score, candidate for outcome y),
##CBINDEX (corruption/bureaucracy index, candidate predictor z).
##This makes later modeling easier by focusing on just the variables we need.
names(attributes(small_dat))
attr(small_dat, "expansion.fields") <- NULL
attr(small_dat, "data.label") <- NULL
attr(small_dat, "val.labels") <- NULL
attr(small_dat, "var.labels") <- NULL
attr(small_dat, "label.table") <- NULL
attr(small_dat, "formats") <- NULL
attr(small_dat, "types") <- NULL

##These lines are cleaning the imported Stata dataset by removing unnecessary attributes so that the data behaves like a standard R object.

##Because the file came from Stata (.dta), the imported tibble carries extra labels/metadata. These attributes don’t affect the numbers but can interfere with modeling functions. The code explicitly removes them.

## This looks promising: https://modelr.tidyverse.org/reference/crossv_mc.html
## https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom
## https://www.tmwr.org/software-modeling.html

## library(tidymodels) ## this looked great but wasn't sure about how to apply
## it with loess
## cv1 <- vfold_cv(small_dat,v=10) (could use tidymodels::vfold_cv() instead of modelr::crossv_kfold())

### My Note: This code prepares a smaller dataset for cross-validation. It loads modelr to enable tidy CV functions, then selects only the relevant variables (Nation, Politystand2014, CBINDEX). Because the data came from Stata, it still carries extra attributes; these are removed to avoid problems with modeling. At this stage, the data are clean and ready for k-fold cross-validation, which can be done either with modelr::crossv_kfold() or, alternatively, tidymodels::vfold_cv().

small_dat <- select(dat, Nation, Politystand2014, CBINDEX)
# remove Stata attributes …
attr(small_dat, "types") <- NULL

small_dat <- small_dat |>
  tidyr::drop_na(Politystand2014, CBINDEX) |>
  dplyr::filter(is.finite(CBINDEX), is.finite(Politystand2014))

plot_dat <- small_dat

try_span <- function(s, f, cvobj) {
  ## s is a span (see the loess help page)
  ## f is the fold number (an integer)
  ## cvobj is an object from the crossv_kfold() function
  train_idx <- cvobj$train[[f]][["idx"]]
  train_dat <- cvobj$train[[f]][["data"]][train_idx, ]
  test_idx <- cvobj$test[[f]][["idx"]]
  test_dat <- cvobj$test[[f]][["data"]][test_idx, ]
  ## setting deg=1 and family="symmetric" but those could change
  ## Hard coding in the y~x formula variables here for ease.
  
  res <- loess(Politystand2014 ~ CBINDEX,
                #span = s, deg = 1, the argument name is degree
             span = s, degree = 1,
             family = "symmetric",
             data = train_dat,
             control = loess.control(surface = "direct"))

  ## Predict onto the test data
  pred_test <- predict(res, newdata = test_dat)
  ## How well did this approach predict the actual test data outcomes.
  resids <- test_dat$Politystand2014 - pred_test
  ## see also broom::augment(res,newdata=test_dat)
  ## see also modelr::rmse(res,data=test_dat)
  ## Calculate something very close to sum(resids^2) (mean(resids^2) =
  ## sum(resids^2)/length(resids).
  my_rmse <- sqrt(mean(resids^2, na.rm = TRUE))
  return(my_rmse)
}
### My note: This function performs one fold of cross-validation for a given LOESS span. It fits a LOESS model of Politystand2014 on CBINDEX using the training data from fold f, predicts outcomes on the test set, and returns the root mean squared error (RMSE). Repeating this across folds and span values allows us to evaluate which smoothing parameter achieves the best out-of-sample predictive accuracy.

set.seed(12355)
## could do this multiple time times too for different seeds
cv1 <- crossv_kfold(small_dat, 10)

## Check out span=2/3
thermse_for_thespan <- sapply(seq_along(cv1$.id), function(thefold) {
  try_span(s = 2 / 3, f = thefold, cvobj = cv1)
})
thermse_for_thespan
mean(thermse_for_thespan)

## Make into another function
avg_rmse <- function(the_span) {
  thermse_for_thespan <- sapply(seq_along(cv1$.id), function(thefold) {
    try_span(s = the_span, f = thefold, cvobj = cv1)
  })
  thermse_for_thespan
  mean(thermse_for_thespan)
}

avg_rmse(2/3)


## What is the smallest rmse?
### Grid search?
some_s <- seq(.1, .9, .1)
res1 <- sapply(some_s,function(s){ avg_rmse(s) })
res1_df <- data.frame(the_rmse=res1,span=some_s)
filter(res1_df,the_rmse==min(the_rmse))

## Optimization?
res2 <- optim(par=c(.1),fn=avg_rmse,method="L-BFGS-B",lower=.05,upper=.95,control=list(trace=10))
best_span <- as.numeric(res2$par)
res2$par
res2$value

## Fit with chosen tuning parameter:
## final_res <- loess(Politystand2014 ~ CBINDEX,
##     span = res2$par, deg = 1,
##     family = "symmetric",
##     data = dat)
## summary(final_res)
## preddat <- broom::augment(final_res)
## head(preddat)

library(robustbase)

g <- ggplot(data=plot_dat, aes(x=CBINDEX,y=Politystand2014))+
    geom_point()+
    stat_smooth(method = "loess", span = best_span,
            method.args = list(degree = 1, family = "symmetric",
                               control = loess.control(surface = "direct")),
            se = FALSE, color = "black")+
    stat_smooth(method="loess",span=best_span,method.args=list(degree = 2, family = "symmetric"),se=FALSE, col="green") +
    stat_smooth(method="lm",se=FALSE,color="blue") +
  geom_hline(yintercept = mean(dat$Politystand2014, na.rm = TRUE), color = "purple")
    #stat_function(fun = mean, geom="line", color="purple")+
    stat_smooth(method="lmrob",se=FALSE,color="orange",method.args=list(setting="KS2014"))

print(g)

mod1 <- loess(Politystand2014 ~ CBINDEX,
              span = best_span, degree = 1,
              family = "symmetric",
              data = dat,
              control = loess.control(surface = "direct"))

```

5. Choose another variable that should also relate to $y_i$ and perhaps to
   $z_i$. This variable, which I'll call it $x_i$, should have between 2 and 4
   categories. It could be ordinal or just categorical. Please ensure that R
   understands this variable as a factor variable. You may need to create this
   variable yourself, for example, if you want to convert something like the
   Policy Standardized Score into categories. Or if you just want to take a
   variable that has few categories and convert it into a factor using
   `factor()` or `as.factor()`. Please describe this variable (you can use
   words, tables, single numbers, etc.. to describe this variable alone, in
   one-dimension).

6. Please describe the relationship between this variable and $y_i$ using least
   squares. This relationship will probably involve `lm()` or
   `estimatr::lm_robust()` to take the categorical variable can convert it into
   a series of indicator variables with 1="in category" and 0="not in
   category". Recall that the constant in such a summary is the mean outcome
   for the excluded category (either least squares command will exclude one of
   the categories) and that the other coefficients are the differences between
   the mean outcomes of the excluded category and each other category.

7. Please also describe the relationship between $y_i$ and $z_i$ conditional on
   $x_i$. That is, if `x` is a factor variable and `y` and `z` are numeric
   variable that are (more or less) continuous, fit and interpret the
   coefficients (and/or predictions) from a model using the formula `y~z*x`
   (where the `*` creates an "interaction term" between `z` and `x`. Feel free
   to use plots to make this interpretation in addition to the coefficients.


   <!--Maybe useful:  https://grantmcdermott.com/interaction-effects/ --> 
   <!-- https://thomasleeper.com/margins/reference/margins.html -->



I am not looking for discussion of statistical inference in this exploration.
So, no need to talk about standard errors, p-values or confidence intervals.
Just figuring out more or less complicated descriptions.

## Step 5: Add a categorical variable \(x_i\)

For the categorical factor \(x_i\), I created a binary grouping of governance quality (`CBINDEX`). Countries below the median CBINDEX are labeled **Low governance**, and those above are **High governance**. This ensures 2 balanced categories.

```{r}
dat <- dat |>
  dplyr::mutate(x_group = ifelse(CBINDEX < median(CBINDEX, na.rm=TRUE),
                                 "Low governance", "High governance")) |>
  dplyr::mutate(x_group = factor(x_group))

# One-dimensional description
table(dat$x_group, useNA="ifany")

# Visualization
ggplot(dat, aes(x_group)) +
  geom_bar() +
  labs(x="Governance group (x)", y="Number of countries")
#Roughly half of the countries fall into each governance group, giving a simple categorical split suitable for interaction analysis
```


## Step 6: Relationship between \(x_i\) and outcome \(y_i\)

#Next, I describe how democracy scores vary across governance groups. A simple least squares model shows the mean difference in `Politystand2014` between Low vs High governance groups.

```{r}
mod_x <- lm(Politystand2014 ~ x_group, data = dat)
broom::tidy(mod_x)

ggplot(dat, aes(x_group, Politystand2014)) +
  geom_boxplot() +
  labs(x="Governance group (x)", y="Democracy score (y)")
  
```

## Step 7: Conditional relationship \(y \sim z * x\)

Finally, I consider whether the slope of governance (`CBINDEX`) predicting democracy (`Politystand2014`) depends on the governance group (`x_group`). This is done with an interaction model.

```{r}
mod_int <- lm(Politystand2014 ~ CBINDEX * x_group, data = dat)
broom::tidy(mod_int)

ggplot(dat, aes(CBINDEX, Politystand2014, color=x_group)) +
  geom_point(alpha=0.7) +
  geom_smooth(method="lm", se=FALSE) +
  labs(title="Democracy vs Governance by group",
       x="Governance index (z)", y="Democracy score (y)")
```

# References
